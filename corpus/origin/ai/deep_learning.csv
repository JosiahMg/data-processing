question,answer
什么是卷积,wx web
什么是池化,wx web
为什么引入非线性激励函数？,深度学习的前提是神经网络的隐层加上了非线性激活函数，提升了模型的非线性表达能力，使得神经网络可以逼近任意复杂的函数。
激活函数的作用,深度学习的前提是神经网络的隐层加上了非线性激活函数，提升了模型的非线性表达能力，使得神经网络可以逼近任意复杂的函数。
为什么ReLu要好过于tanh和sigmoid function？,wx web
如何解决RNN梯度爆炸和弥散的问题？,LSTM GRU
如何解决RNN梯度消失和梯度爆炸？,LSTM GRU